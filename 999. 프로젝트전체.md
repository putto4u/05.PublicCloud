### 글로벌 확장을 고려한 단계별 IaC 디렉토리 설계 및 무결점 파이프라인 (Project: awskr01)

단일 스포크(Spoke, 네트워크의 말단 노드) 클러스터에서 시작하여 향후 3개 대륙을 연결하는 글로벌 허브 앤 스포크(Hub & Spoke)[^1] 아키텍처로 진화하기 위해서는, 인프라 코드의 디렉토리 구조 자체가 **'작업의 순서(Workflow)'**와 **'미래의 확장성(Scalability)'**을 동시에 표현해야 합니다.

현재는 단일 스포크만 운영하지만, 조만간 한국 리전에 허브(Hub, 네트워크의 중앙 집중점)를 신설하고 네트워크 통제권(NAT Gateway, Bastion Host 등)을 이관해야 합니다. 이를 마이그레이션(Migration, 시스템 이전) 작업에 따른 다운타임(Downtime, 시스템 가동 불가 시간) 없이 수행하기 위해, 사전 작업(IAM, 인증)부터 애플리케이션 배포까지 모든 과정을 코드로 정의하고 작업 순서가 반영된 넘버링(Numbering) 규칙을 부여합니다.

---

### 1. 작업 순서 기반 전체 프로젝트 디렉토리 구조 (Current & Future)

인프라스트럭처의 의존성 흐름에 따라 `000`부터 `040`까지 디렉토리 번호를 부여하여, 실행 순서를 직관적으로 강제합니다.

```text
awskr01/
├── scripts/                                # 방어적 파이프라인 스크립트 모음
│   ├── 01-current-spoke-build.sh           # [현재] 단일 스포크 구축용
│   ├── 02-current-spoke-destroy.sh         # [현재] 단일 스포크 폐기용
│   ├── 03-future-global-build.sh           # [미래] 글로벌 3개 리전 일괄 구축용
│   └── 04-future-global-destroy.sh         # [미래] 글로벌 3개 리전 일괄 폐기용
│
├── infrastructure/                         # Terragrunt 기반 클라우드 인프라 영역
│   ├── modules/                            # [순수 Terraform] 논리적으로 분리된 재사용 템플릿
│   │   ├── aws-network-hub/                # TGW, 중앙 NAT Gateway, 공유 Bastion 등
│   │   ├── aws-network-spoke/              # ★ 핵심: 변수(enable_nat)로 NAT 토글 기능 구현
│   │   ├── aws-eks/
│   │   └── aws-rds/
│   │
│   └── live/                               # [Terragrunt HCL] 실제 환경 배포 정의
│       ├── terragrunt.hcl                  # 전역 설정 (S3 State Bucket 자동 생성 등)
│       │
│       ├── 000-prerequisites/              # [사전 작업] AWS IAM, OIDC, KMS 등 기초 공사
│       │   └── ap-northeast-2/
│       │       ├── iam-roles/terragrunt.hcl
│       │       └── ecr-repos/terragrunt.hcl
│       │
│       ├── 010-hub/                        # [미래 이전 영역] 당장은 비워두지만, 조만간 구축됨
│       │   └── ap-northeast-2/
│       │       ├── network/terragrunt.hcl  # 향후 중앙 NAT Gateway가 위치할 곳
│       │       └── tgw/terragrunt.hcl      # 글로벌 통신용 Transit Gateway
│       │
│       └── 020-spokes/                     # [현재 운영 영역] 워크로드 클러스터
│           ├── ap-northeast-2/             # 한국 리전 (현재 단일 스포크)
│           │   ├── network/terragrunt.hcl  # 현재: enable_nat=true / 허브 연결 시: false로 변경
│           │   ├── eks/terragrunt.hcl
│           │   └── rds/terragrunt.hcl
│           │
│           ├── us-east-1/                  # [미래 확장] 미국 동부
│           └── eu-west-2/                  # [미래 확장] 영국 런던
│
└── kubernetes/                             # EKS 내부 배포 매니페스트 (YAML)
    ├── 030-k8s-config/                     # [연결 작업] 인프라와 K8s를 연결하는 설정
    │   ├── aws-auth.yaml                   # IAM Role과 K8s RBAC 매핑
    │   └── service-accounts.yaml           # IRSA (IAM Roles for Service Accounts) 연결
    │
    └── 040-k8s-workloads/                  # [워크로드] 실제 서비스 및 애드온
        ├── addons/                         # AWS LBC, External-DNS
        ├── backend/                        # 백엔드 API 서버 (HPA 포함)
        └── frontend/                       # 프론트엔드 웹 서버 (Ingress 포함)


```

---

### 2. 현재 단계 (단일 스포크) 파이프라인 스크립트

현재 구축된 `000` (사전 작업), `020` (한국 스포크), `030`, `040` (쿠버네티스) 디렉토리만 실행하며, 아직 존재하지 않는 `010-hub`나 타 리전 코드는 에러 없이 통과(Bypass)하도록 설계된 방어적 스크립트입니다.

**구축 스크립트: `scripts/01-current-spoke-build.sh**`

```bash
#!/bin/bash
set -e # 에러 발생 시 즉시 중단

echo "=== 1. 사전 인프라(IAM 등) 구성 (000-prerequisites) ==="
if [ -d "../infrastructure/live/000-prerequisites" ]; then
    cd ../infrastructure/live/000-prerequisites
    terragrunt run-all apply --terragrunt-non-interactive
    cd - > /dev/null
fi

# 010-hub는 현재 비어있거나 없으므로 검사 후 안전하게 통과
echo "=== 2. 허브 인프라 구성 (010-hub) - 현재 생략 ==="

echo "=== 3. 단일 스포크 인프라 구성 (020-spokes/ap-northeast-2) ==="
# 과금 주의: NAT Gateway(시간당 $0.045), EKS(시간당 $0.10), RDS 과금 시작
if [ -d "../infrastructure/live/020-spokes/ap-northeast-2" ]; then
    cd ../infrastructure/live/020-spokes/ap-northeast-2
    terragrunt run-all apply --terragrunt-non-interactive
    cd - > /dev/null
fi

echo "=== 4. EKS 자격 증명 및 쿠버네티스 연결 (030-k8s-config) ==="
if aws eks describe-cluster --region ap-northeast-2 --name awskr01-spoke-eks > /dev/null 2>&1; then
    aws eks update-kubeconfig --region ap-northeast-2 --name awskr01-spoke-eks
    [ -d "../kubernetes/030-k8s-config" ] && kubectl apply -f ../kubernetes/030-k8s-config/
fi

echo "=== 5. 마이크로서비스 배포 (040-k8s-workloads) ==="
# 과금 주의: ALB(로드 밸런서 용량 단위) 과금 시작
if [ -d "../kubernetes/040-k8s-workloads" ]; then
    [ -d "../kubernetes/040-k8s-workloads/addons" ] && kubectl apply -f ../kubernetes/040-k8s-workloads/addons/
    sleep 15
    [ -d "../kubernetes/040-k8s-workloads/backend" ] && kubectl apply -f ../kubernetes/040-k8s-workloads/backend/
    [ -d "../kubernetes/040-k8s-workloads/frontend" ] && kubectl apply -f ../kubernetes/040-k8s-workloads/frontend/
fi
echo "✅ 현재 단계 단일 스포크 구축 완료"

```

**폐기 스크립트: `scripts/02-current-spoke-destroy.sh**`

```bash
#!/bin/bash
set -e

echo "=== 1. 쿠버네티스 워크로드 회수 (040 -> 030 역순) ==="
aws eks update-kubeconfig --region ap-northeast-2 --name awskr01-spoke-eks || true
if [ -d "../kubernetes/040-k8s-workloads" ]; then
    kubectl delete -f ../kubernetes/040-k8s-workloads/frontend/ --ignore-not-found=true || true
    kubectl delete -f ../kubernetes/040-k8s-workloads/backend/ --ignore-not-found=true || true
    kubectl delete -f ../kubernetes/040-k8s-workloads/addons/ --ignore-not-found=true || true
    echo "AWS 리소스(ALB 등) 삭제 대기 (90초)..."
    sleep 90
fi

echo "=== 2. 단일 스포크 인프라 회수 (020-spokes/ap-northeast-2) ==="
if [ -d "../infrastructure/live/020-spokes/ap-northeast-2" ]; then
    cd ../infrastructure/live/020-spokes/ap-northeast-2
    terragrunt run-all destroy --terragrunt-non-interactive
    cd - > /dev/null
fi

echo "=== 3. 사전 인프라 회수 (000-prerequisites) ==="
if [ -d "../infrastructure/live/000-prerequisites" ]; then
    cd ../infrastructure/live/000-prerequisites
    terragrunt run-all destroy --terragrunt-non-interactive
    cd - > /dev/null
fi
echo "✅ 현재 단계 단일 스포크 폐기 완료 (과금 중단)"

```

---

### 3. 향후 단계 (글로벌 3개 리전 허브 앤 스포크) 파이프라인 스크립트

조만간 한국 리전에 허브(010-hub)를 구축하고, 이어서 3개 대륙의 스포크를 한 번에 찍어낼 때 사용할 미래형 스크립트입니다. `terragrunt run-all`의 강력한 동시성을 활용합니다.

**글로벌 구축 스크립트: `scripts/03-future-global-build.sh**`

```bash
#!/bin/bash
set -e

# 000 사전작업 (IAM 등) 일괄 배포
[ -d "../infrastructure/live/000-prerequisites" ] && cd ../infrastructure/live/000-prerequisites && terragrunt run-all apply --terragrunt-non-interactive && cd - > /dev/null

# 010 글로벌 허브 통신망 배포 (TGW 등)
# 과금 주의: TGW (시간당 $0.05 및 데이터 요금) 과금 시작
echo "=== 글로벌 통신 허브망 구축 ==="
[ -d "../infrastructure/live/010-hub" ] && cd ../infrastructure/live/010-hub && terragrunt run-all apply --terragrunt-non-interactive && cd - > /dev/null

# 020 전 세계 스포크 동시 배포 (한국, 미국, 영국 병렬 처리)
# 과금 주의: 각 리전별 EKS, RDS 3배수 과금
echo "=== 3개 리전 스포크 워크로드 동시 구축 ==="
[ -d "../infrastructure/live/020-spokes" ] && cd ../infrastructure/live/020-spokes && terragrunt run-all apply --terragrunt-non-interactive && cd - > /dev/null

# 이후 리전별 루프(Loop)를 돌며 K8s 030, 040 배포하는 로직 추가 (지면상 생략)
echo "✅ 글로벌 허브 앤 스포크 인프라 배포 완료"

```

---

### 4. 핵심 아키텍처 원리: 조만간 실행될 허브(Hub) 마이그레이션 전략

현재 `020-spokes/ap-northeast-2/network` 안에는 스포크 자체가 외부와 통신하기 위해 임시로 만들어진 NAT Gateway가 동작하고 있습니다. 향후 `010-hub` 디렉토리에 허브망을 구축한 후, 스포크를 허브로 종속시킬 때 코드는 다음과 같이 단 한 줄만 변경됩니다.

1. `020-spokes/ap-northeast-2/network/terragrunt.hcl` 파일을 엽니다.
2. 입력 변수를 `inputs = { enable_nat = true }`에서 `inputs = { enable_nat = false, tgw_id = "tgw-xxxxx" }`로 수정합니다.
3. 파이프라인을 재실행합니다.
4. **결과:** 인프라 파괴 없이, 기존 스포크에 있던 NAT Gateway만 깔끔하게 삭제되며, 통신 라우팅 테이블이 허브의 TGW를 바라보게 됩니다. 이것이 디렉토리를 미리 쪼개놓고 변수로 제어하는 진정한 **마이그레이션 제로(Zero-Migration)** 설계입니다.

---

**[주석]**

* [^1] **Hub & Spoke (허브 앤 스포크):** 자전거 바퀴의 중심축(Hub)과 바퀴살(Spoke)에서 유래한 네트워크 설계 패턴. 중앙의 Hub VPC를 통해 모든 통신이 통제되며, Spoke VPC들은 Hub를 거쳐 서로 통신하거나 외부로 나갑니다. 네트워크 보안 관리와 확장에 매우 유리합니다.

Next Step: 000-prerequisites 디렉토리 구성 (IAM OIDC 통합 및 S3 State Backend 구축 코드 작성)

---

수정이 완료되었습니다. 프로젝트 명칭이 **awskr01**로 일괄 변경되었습니다.

Next Step: 000-prerequisites 디렉토리 구성 (IAM OIDC 통합 및 S3 State Backend 구축 코드 작성)
=================

### 실무 인프라스트럭처 에즈 코드(IaC) 프로젝트 초기 셋업 및 GitHub(깃허브) 보안 연동 (Project: awskr01)

클라우드 인프라를 코드로 다루는 프로젝트를 시작할 때, 가장 먼저 수행해야 할 작업은 로컬 PC(작업자 컴퓨터)에 안전한 작업 공간을 격리하고, 형상 관리 도구인 Git(깃)을 초기화하여 원격 저장소인 GitHub(깃허브)와 연동하는 것입니다. 이 과정에서 실수로 클라우드 접속 키(Credential)나 상태 파일(State File)이 업로드되지 않도록 방어벽(`.gitignore`)을 치는 것이 핵심입니다.

---

### 1단계: 로컬 작업 디렉토리 생성 및 Git(깃) 초기화

터미널(Terminal)을 열고 프로젝트를 진행할 최상위 디렉토리를 생성한 뒤, 해당 폴더를 Git 저장소로 선언합니다.

```bash
# 1. 홈 디렉토리 또는 원하는 작업 공간으로 이동
cd ~

# 2. 프로젝트 최상위 폴더 생성 및 이동
mkdir awskr01
cd awskr01

# 3. 빈 Git 저장소 초기화 (이 폴더의 변경 사항 추적 시작)
git init


```

---

### 2단계: 클라우드 보안의 핵심, `.gitignore` 파일 작성

`git init` 직후, 어떠한 코드도 작성하기 전에 반드시 `.gitignore` 파일을 먼저 생성해야 합니다. 이 파일에 정의된 확장자나 폴더는 GitHub로 절대 전송되지 않습니다. Terraform(테라폼) 운영 시 발생하는 민감한 정보(상태 파일, 임시 캐시, 로컬 환경 변수 등)를 원천 차단합니다.

프로젝트 최상위 경로(`awskr01/`)에 `.gitignore` 파일을 생성하고 아래 내용을 입력하여 저장합니다.

```text
# .gitignore 파일 내용

# 1. Terraform 및 Terragrunt 로컬 캐시 디렉토리
.terraform/
.terragrunt-cache/
**/.terraform/*
**/.terragrunt-cache/*

# 2. 인프라 실물 정보가 평문으로 담긴 상태 파일 (절대 업로드 금지)
*.tfstate
*.tfstate.*

# 3. 크래시 로그 및 재정의 파일
crash.log
override.tf
override.tf.json
*_override.tf
*_override.tf.json

# 4. 자격 증명 및 로컬 환경 변수 파일
*.tfvars
*.tfvars.json
.env
secret.tfvars
credentials.csv

# 5. OS 생성 임시 파일 (macOS 및 Windows)
.DS_Store
Thumbs.db


```

---

### 3단계: GitHub(깃허브) 원격 저장소(Remote Repository) 생성 및 연결

로컬에 안전망을 구축했으므로, 이 코드를 백업하고 팀원과 협업할 수 있는 GitHub 원격 저장소를 연결합니다.

1. **GitHub 웹사이트 접속:** 본인의 GitHub 계정으로 로그인합니다.
2. **새 저장소(New Repository) 생성:**

* `Repository name`: `awskr01` (로컬 폴더명과 일치시키는 것을 권장)
* `Public` 또는 `Private` 선택 (실무 보안을 위해 가급적 `Private` 권장)
* **주의:** `Add a README file`이나 `Add .gitignore` 옵션은 **체크하지 않고** 빈 저장소 상태로 `Create repository` 버튼을 클릭합니다.

3. **로컬과 원격 저장소 연결 (터미널 작업):**
GitHub 화면에 나타난 저장소 주소(URL)를 복사한 뒤, 터미널에서 아래 명령어를 순차적으로 실행합니다.

```bash
# 1. 현재까지의 파일(.gitignore 등)을 스테이징 영역에 추가
git add .

# 2. 첫 번째 커밋(Commit, 확정 저장) 수행
git commit -m "chore: 프로젝트 초기화 및 .gitignore 설정"

# 3. 기본 브랜치(Branch, 작업 가지) 이름을 'main'으로 변경
git branch -M main

# 4. GitHub 원격 저장소 주소 등록 (아래 URL은 본인의 GitHub 주소로 변경해야 함)
git remote add origin https://github.com/본인계정/awskr01.git

# 5. 로컬의 main 브랜치 코드를 원격 저장소로 밀어넣기(Push)
git push -u origin main


```

---

### 4단계: AWS CLI(Command Line Interface, 명령줄 인터페이스) 자격 증명 안전 구성

GitHub 연동이 끝났다면, Terraform이 AWS 클라우드 자원을 생성할 수 있도록 터미널에 통행증을 발급해야 합니다. 앞서 언급한 대로 코드에 키를 하드코딩(Hard-coding)하지 않고 로컬 프로필에 안전하게 캐싱(Caching)합니다.

터미널에서 아래 명령어를 실행하고, AWS IAM(Identity and Access Management, 식별 및 액세스 관리) 콘솔에서 발급받은 키를 입력합니다.

```bash
aws configure


```

* `AWS Access Key ID`: 발급받은 액세스 키 입력
* `AWS Secret Access Key`: 발급받은 시크릿 키 입력
* `Default region name`: `ap-northeast-2` (한국 서울 리전)
* `Default output format`: `json`

> **AWS 과금 및 보안 주의:** `aws configure` 자체는 무료지만, 이 통행증을 얻은 Terraform이 이후 EC2(Elastic Compute Cloud, 탄력적 컴퓨팅 클라우드)나 NAT Gateway(Network Address Translation Gateway, NAT 게이트웨이) 구축 코드를 실행하는 순간 권한이 즉시 행사되며 AWS 계정에 과금이 발생하기 시작합니다. 해당 키(Access/Secret)가 담긴 `~/.aws/credentials` 파일은 절대 외부로 유출되어서는 안 됩니다.

---

모든 기초 환경 구성과 보안 방어벽 설정이 완료되었습니다. 이제 이 안전한 디렉토리 위에서 첫 번째 인프라 코드를 작성할 준비가 되었습니다.

Next Step: `000-prerequisites` 디렉토리 하위의 Terragrunt 전역 설정 파일(`terragrunt.hcl`) 및 ECR/IAM 모듈 코드 작성

---

수정이 완료되었습니다. 모든 프로젝트 명칭이 **awskr01**로 일치하도록 변경되었습니다.

Next Step: `000-prerequisites` 디렉토리 하위의 Terragrunt 전역 설정 파일(`terragrunt.hcl`) 및 ECR/IAM 모듈 코드 작성

==================================
### 실무 환경 디렉토리 생성 및 일일 작업(Daily Workflow) 파이프라인 가이드 (Project: awskr01)

앞서 정의한 코드를 바탕으로, 실제 환경에서 어디에 폴더를 만들고 파일을 어떻게 위치시켜야 하는지 물리적인 작업 절차를 안내합니다. 아울러 클라우드 과금을 방지하기 위해 매일 작업을 시작할 때 인프라를 올리고, 작업이 끝나면 코드를 저장(Git Commit)한 뒤 모두 파괴(Destroy)하고 퇴근하는 실무형 일일 파이프라인(Daily Pipeline) 실행 방법을 구성합니다.

---

### 작업 환경 준비: 로컬 PC(Local PC) 기반의 IaC 개발 환경 세팅

최초의 인프라스트럭처 에즈 코드(IaC - Infrastructure as Code) 작성 및 실행 작업은 AWS 상의 EC2(Elastic Compute Cloud, 탄력적 컴퓨팅 클라우드) 인스턴스를 별도로 만들어서 진행하는 것이 아닙니다. 코딩의 편의성(VS Code 등 에디터 활용)과 불필요한 서버 유지 비용(과금)을 방지하기 위해, **작업자의 로컬 PC(MacBook, Windows Git Bash, 리눅스 터미널 등)에서 직접 수행**하는 것이 글로벌 실무의 표준입니다.

작업을 시작하기 전, 로컬 PC 터미널에 다음 도구들이 설치되어 있고 AWS 계정과 연동되어 있어야 합니다.

1. **AWS CLI(Command Line Interface, 명령줄 인터페이스):** AWS 자원을 제어하기 위한 도구입니다. 로컬 PC에 설치한 후 터미널에서 `aws configure` 명령어를 입력하여 IAM(Identity and Access Management, 식별 및 액세스 관리) 관리자 권한을 가진 사용자의 Access Key(액세스 키)와 Secret Key(시크릿 키)를 등록해야 테라폼이 AWS에 접근할 수 있습니다.
2. **Terraform(테라폼) 및 Terragrunt(테라그런트):** 인프라 코드를 실행하는 핵심 바이너리 파일입니다. 로컬 PC의 환경 변수(Path)에 등록되어 터미널 어디서든 실행 가능해야 합니다.
3. **Git(깃):** 코드 형상 관리를 위한 필수 버전 제어 시스템입니다.

---

### 작업 공간 초기화 및 디렉토리 생성 (터미널 작업)

가장 먼저 프로젝트의 뼈대가 될 디렉토리 구조를 생성해야 합니다. 터미널을 열고 로컬 PC의 본인 작업 공간(예: `~/workspace` 또는 `C:\workspace`)으로 이동한 뒤 아래 명령어들을 순차적으로 실행하여 폴더들을 생성합니다.

```bash
# 1. 최상위 프로젝트 폴더 생성 및 이동
mkdir -p awskr01
cd awskr01

# 2. 인프라 모듈(순수 테라폼) 및 Live(테라그런트) 디렉토리 생성
mkdir -p infrastructure/modules/prepare
mkdir -p infrastructure/live/000-prepare/ap-northeast-2

# 3. 형상 관리를 위한 Git 초기화
git init
# 현재 브랜치(master)의 이름을 main으로 변경
git branch -m master main

```

---

### 각 파일별 정확한 생성 위치 및 코드 삽입

생성된 디렉토리에 맞게 앞서 설계했던 사전 작업(Prepare)의 전체 코드를 아래에 통합하여 제공합니다. VS Code 등의 에디터를 사용하여 지정된 경로에 정확히 파일을 생성하고 코드를 작성하십시오.

**파일 1: 최상위 전역 상태 설정 파일**

* **생성 위치:** `infrastructure/live/terragrunt.hcl`
* **작업 내용:** 하위의 모든 디렉토리(Spoke, Hub 등)가 공통으로 상속받는 전역 상태 파일 설정입니다. S3(Simple Storage Service, 단순 스토리지 서비스) 버킷 이름은 반드시 전 세계에서 유일한 이름으로 수정해야 합니다.

```hcl
remote_state {
  backend = "s3"
  generate = {
    path      = "backend.tf"
    if_exists = "overwrite_terragrunt"
  }
  config = {
    # 과금 주의: S3 버킷에 상태 파일이 저장되며, 저장된 용량 및 요청 횟수에 따라 소액의 종량제 요금이 발생합니다.
    bucket         = "awskr01-tfstate-apne2-12345" # 본인만의 고유한 이름으로 변경 필수
    key            = "${path_relative_to_include()}/terraform.tfstate"
    region         = "ap-northeast-2"
    encrypt        = true
    
    # 과금 주의: 동시성 제어를 위한 DynamoDB 테이블이 생성되며, 읽기/쓰기 용량에 따른 요금이 발생합니다.
    dynamodb_table = "awskr01-tflock-table"
  }
}

# 모든 리소스에 공통으로 들어갈 글로벌 태그 정의
inputs = {
  default_tags = {
    Project     = "awskr01-Hub-Spoke"
    ManagedBy   = "Terragrunt"
  }
}

```

**파일 2: 사전 작업 모듈 파일 (순수 테라폼)**

* **생성 위치:** `infrastructure/modules/prepare/main.tf`
* **작업 내용:** ECR(Elastic Container Registry, 엘라스틱 컨테이너 레지스트리) 저장소 생성 및 EKS(Elastic Kubernetes Service, 엘라스틱 쿠버네티스 서비스) 클러스터용 IAM 역할 생성 코드를 이 파일에 저장합니다.

```terraform
# 1. ECR (Elastic Container Registry) 생성
# 프론트엔드와 백엔드의 도커(Docker) 이미지를 저장할 중앙 보관소입니다.
# 과금 주의: ECR은 저장된 이미지의 용량(GB당 월 $0.10) 및 데이터 전송량에 따라 과금이 발생합니다.

# 백엔드용 이미지 저장소 정의
resource "aws_ecr_repository" "backend_repo" {
  name                 = "awskr01-backend" # 저장소 이름 설정
  image_tag_mutability = "MUTABLE"           # 이미지 태그 변경 가능 여부 (MUTABLE: 동일 태그 덮어쓰기 허용)

  # 이미지 보안 설정
  image_scanning_configuration {
    scan_on_push = true # 이미지가 푸시(Push)될 때마다 보안 취약점을 자동으로 스캔함
  }
}

# 프론트엔드용 이미지 저장소 정의
resource "aws_ecr_repository" "frontend_repo" {
  name                 = "awskr01-frontend"
  image_tag_mutability = "MUTABLE"
}


# 2. EKS Cluster IAM Role
# 쿠버네티스 컨트롤 플레인(Control Plane)이 AWS 인프라(EC2, 로드밸런서 등)를 제어하기 위해 필요한 권한입니다.
# EKS 클러스터용 IAM Role(Identity and Access Management Role, 신뢰 관계 설정) 생성
resource "aws_iam_role" "eks_cluster_role" {
  name = "awskr01-eks-cluster-role"

# 이 역할(Role)을 누구(EKS 서비스)가 사용할 수 있는지 정의하는 신뢰 정책
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"   # sts 토큰,  역할을 맡을 수 있도록 허용하는 동작
      Effect = "Allow"
      Principal = {
        Service = "eks.amazonaws.com"  # EKS 서비스가 이 역할을 사용하도록 지정
      }
    }]
  })
}

# 생성한 역할에 실제 권한(Policy) 부여
# AWS IAM 역할에 특정 정책(Policy)을 부착(Attachment)하는 리소스 정의
resource "aws_iam_role_policy_attachment" "eks_cluster_policy" {
  # AmazonEKSClusterPolicy: EKS 클러스터가 AWS 리소스를 관리하는 데 필요한 표준 권한 ARN(Amazon Resource Name)
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
  
  # 위에서 정의한 aws_iam_role.eks_cluster_role 리소스의 이름을 참조하여 해당 역할에 권한을 연결
  role       = aws_iam_role.eks_cluster_role.name 
}

```

**파일 3: 한국 리전 사전 작업 실행 파일 (테라그런트)**

* **생성 위치:** `infrastructure/live/000-prepare/ap-northeast-2/terragrunt.hcl`
* **작업 내용:** 최상위 설정을 상속(`include`)받고, 모듈의 경로(`source`)를 연결하는 코드를 이 파일에 저장합니다.

```hcl
# 현재 위치에서 상위 폴더를 거슬러 올라가며 최상위 terragrunt.hcl(S3/DynamoDB 설정)을 찾아 상속받음
include {
  path = find_in_parent_folders()
}

# 실제 인프라 리소스를 정의한 테라폼 모듈 소스 코드의 상대 경로를 지정
terraform {
  source = "../../../../modules/prepare"
}

# 해당 모듈의 variables.tf에 정의된 변수들에 실제 값을 주입하는 블록
inputs = {
  # 리소스가 생성될 AWS 지역을 서울 리전으로 지정
  region      = "ap-northeast-2"
  
  # 현재 환경의 식별자 이름을 프로젝트 명칭에 맞춰 설정
  environment = "awskr01-prepare"
}
```

---

### 실행 방법: 작업 시작 및 테스트 (Day 1 - Start)

파일 배치가 완료되었으면, 해당 리전의 `live` 디렉토리로 이동하여 테라그런트 명령어를 통해 AWS 상에 리소스를 실제 프로비저닝(Provisioning)하고 테스트합니다.

```bash
# 1. 실행할 대상 디렉토리로 이동
cd infrastructure/live/000-prepare/ap-northeast-2

# 2. 테라그런트 초기화 (플러그인 다운로드 및 S3/DynamoDB 백엔드 자동 생성)
terragrunt init

# 3. 배포 계획 확인 및 실제 배포 적용
# 과금 주의: 이 명령어가 성공하면 S3, DynamoDB, ECR 등이 생성되어 과금이 시작될 수 있습니다.
terragrunt apply

```

* 명령어 실행 중 `Are you sure you want to perform these actions?` 라는 프롬프트가 나오면 `yes`를 입력하여 승인합니다.
* 에러 없이 `Apply complete!` 메시지가 나오면 AWS 콘솔에 접속하여 IAM Role과 ECR 리포지토리가 잘 만들어졌는지 테스트 및 확인합니다.

---

### 일일 작업 종료 및 과금 방지 파이프라인 (Day 1 - End)

작업과 테스트가 무사히 끝났다면, 불필요한 과금을 막기 위해 생성된 자원을 모두 파괴하고 현재까지의 코드를 Git에 안전하게 저장합니다.

```bash
# 1. 인프라 자원 안전하게 일괄 폐기 (과금 중단)
# 이 명령을 실행해도 우리가 작성한 로컬의 '코드'는 지워지지 않으며, AWS 상의 '실물 자원'만 지워집니다.
terragrunt destroy

```

* `yes`를 입력하여 폐기를 승인합니다. `Destroy complete!`를 반드시 확인하십시오.
* **참고:** `terragrunt destroy`를 하더라도 중앙 상태 관리를 위해 Terragrunt가 자동으로 만든 최상위 S3 버킷과 DynamoDB 테이블은 안전을 위해 삭제되지 않고 유지됩니다. (이 유지 비용은 월 1달러 미만의 극소액입니다.)

```bash
# 2. 작업 폴더 최상단으로 이동
cd ../../../../

# 3. 오늘 작업한 코드를 Git(형상 관리 저장소)에 저장
git add .
git commit -m "feat: 000-prepare 모듈 및 terragrunt 설정 완료"
git push origin main  # 깃허브 저장
```

---

### 다음 날 작업 이어서 하기 (Day 2 - Start)

다음 날 다시 로컬 PC를 켜고, 어제 폐기했던 인프라를 다시 살려낸 뒤 그 위에서 다음 단계(예: 020-spokes 네트워크 구축)의 코딩과 테스트를 이어나가는 파이프라인입니다.

```bash
# 1. 어제 작업했던 디렉토리로 이동하여 인프라 즉시 복구 (멱등성 보장)
cd infrastructure/live/000-prepare/ap-northeast-2
terragrunt apply -auto-approve

# 2. 인프라가 완벽히 어제 상태로 복원되었으므로, 다음 단계 폴더 생성 후 작업 진행
cd ../../
mkdir -p 020-spokes/ap-northeast-2/network
# ... (다음 단계 코딩 시작) ...

```

이와 같은 **"로컬 PC에서 코드 작성 -> 배포(Apply) 및 테스트 -> 형상 관리(Commit) -> 자원 파괴(Destroy)"**의 반복적인 사이클(Cycle)이 클라우드 네이티브(Cloud Native) 엔지니어들이 막대한 과금을 피하면서도 대규모 인프라를 안전하게 설계하는 실무의 핵심 파이프라인입니다.

---

Next Step: 단일 스포크(Spoke) VPC 구축 및 NAT Gateway 동적 토글(Toggle)을 적용한 네트워크 모듈 구성 및 적용 방법

---

### 인프라스트럭처 실행 메커니즘: Terragrunt의 상속과 실행 원리

질문하신 **`infrastructure/live/terragrunt.hcl`**과 **`main.tf`**는 별도로 독립 실행하는 파일이 아니라, `terragrunt apply` 명령을 내리는 순간 **자동으로 결합되어 실행**됩니다. 그 작동 원리를 이해하는 것이 중요합니다.

---

### 1. `infrastructure/live/terragrunt.hcl` (최상위 설정)은 어떻게 실행되나?

이 파일은 **"설정의 부모"** 역할을 합니다.

* **실행 방식:** 우리가 `infrastructure/live/000-prepare/ap-northeast-2/` 디렉토리에서 `terragrunt apply`를 실행하면, 해당 폴더의 `terragrunt.hcl` 안에 있는 `include { path = find_in_parent_folders() }` 코드가 작동합니다.
* **결과:** Terragrunt는 상위 폴더를 뒤져서 최상위 `terragrunt.hcl`을 찾아냅니다. 그리고 그 안에 정의된 **S3 Backend(백엔드) 설정과 전역 변수(Inputs)**를 현재 실행 위치로 가져와서 합쳐버립니다.
* 따라서, 하위 디렉토리에서 명령을 내리는 것만으로 최상위 설정은 **이미 적용되고 있는 상태**입니다.

---

### 2. `infrastructure/modules/prepare/main.tf` (모듈 코드)는 어떻게 실행되나?

이 파일은 **"설계도"**이며, Terragrunt에 의해 **임시 작업 공간으로 복사**되어 실행됩니다.

* **실행 방식:** 하위 `terragrunt.hcl`의 `terraform { source = "..." }` 설정을 통해 Terragrunt는 `main.tf`가 있는 위치를 파악합니다.
* **결과:** `terragrunt apply`를 입력하면 Terragrunt는 다음 과정을 순식간에 처리합니다.
1. `.terragrunt-cache`라는 숨겨진 임시 폴더를 만듭니다.
2. 그 안에 `modules/prepare/main.tf` 코드를 복사해 넣습니다.
3. 최상위 설정에서 생성하라고 지시한 `backend.tf` 파일을 그 자리에 생성합니다.
4. 그 폴더 안에서 실제 `terraform apply`를 대신 호출합니다.



> **핵심 요약:** 우리가 `live` 폴더의 가장 끝단(Leaf Directory)에서 명령을 내리는 이유는, 그곳이 **설계도(Module)**와 **환경 설정(Root Config)**이 만나서 **실제 자원(Instance)**으로 탄생하는 접점이기 때문입니다.

---

### 3. 일일 작업 시 주의사항 (과금 및 무결성)

* **`terragrunt init`의 중요성:** 최상위 `terragrunt.hcl`의 S3 버킷 이름 등을 변경했다면, 반드시 다시 `init`을 해주어야 백엔드 구성이 동기화됩니다.
* **과금 포인트:** `main.tf`에 정의된 **ECR(Elastic Container Registry, 엘라스틱 컨테이너 레지스트리)** 저장소 자체는 생성 시 비용이 거의 없으나, 나중에 이미지를 푸시하여 저장 용량이 늘어나면 비용이 발생합니다.
* **DynamoDB 테이블:** Terragrunt가 상태 잠금(Locking)을 위해 만드는 DynamoDB는 **`terragrunt destroy`를 해도 삭제되지 않습니다.** 하지만 프리티어 범위 내에서 거의 무상으로 유지되므로 걱정하지 않으셔도 됩니다.

Next Step: 단일 스포크(Spoke) VPC 구축을 위한 `infrastructure/modules/aws-network-spoke` 모듈 작성 및 변수 처리 방법
===================================================



## 2일차: 온프레미스 중심 글로벌 네트워크 설계 및 하이브리드 대응 구축 (Project: awskr01)

오늘의 목표는 사내 구축형 전산실인 온프레미스(On-premises) 대역(**10.10.0.0/16**)을 모든 통신의 기준점으로 삼고, AWS 글로벌 인프라 대역을 대륙별로 순차 할당하는 것입니다. 또한, 시스템 장애에 대비한 고가용성(High Availability)을 확보하기 위해 **2개의 가용 영역(Availability Zone A, C)**에 서브넷(Subnet)을 분산 배치합니다.

### 1. 글로벌 IP 주소 할당 및 서브넷 분할 전략

향후 VPN(Virtual Private Network, 가상 사설망)이나 Direct Connect(다이렉트 커넥트, AWS 전용선 서비스)를 통해 클라우드와 사내 전산망을 연결할 때 발생할 수 있는 IP 주소 충돌(IP Conflict)을 원천 차단하기 위해 대륙별로 대역을 엄격하게 분리합니다.

| 위치 (Role) | 전체 네트워크 대역 (CIDR) | 가용 영역 A (AZ A) | 가용 영역 C (AZ C) | 비고 |
| --- | --- | --- | --- | --- |
| **온프레미스** | **10.10.0.0/16** | - | - | **(기준점)** 사내 IDC 대역 |
| **한국 리전** | **10.20.0.0/16** | 10.20.x.x | 10.20.x.x | 첫 번째 글로벌 스포크 |
| **미국 리전** | **10.30.0.0/16** | 10.30.x.x | 10.30.x.x | 두 번째 글로벌 스포크 |
| **유럽 리전** | **10.40.0.0/16** | 10.40.x.x | 10.40.x.x | 세 번째 글로벌 스포크 |

#### [세부 설계] 한국 리전 스포크 내부 서브넷 (10.20.0.0/16)

각 리전 내부의 네트워크는 외부 통신 여부와 보안 수준에 따라 퍼블릭(Public)과 프라이빗(Private)으로 나뉘며, 가용 영역 A와 C에 쌍(Pair)으로 구성됩니다.

| 서브넷 용도 | 가용 영역 A (AZ A) | 가용 영역 C (AZ C) | 주요 역할 |
| --- | --- | --- | --- |
| **Public** | 10.20.1.0/24 | 10.20.2.0/24 | ALB(애플리케이션 로드 밸런서), NAT Gateway(네트워크 주소 변환 게이트웨이) |
| **Private EKS** | 10.20.10.0/24 | 10.20.11.0/24 | EKS(엘라스틱 쿠버네티스 서비스) 워커 노드 및 애플리케이션 |
| **Private DB** | **10.20.100.0/24** | **10.20.101.0/24** | RDS(관계형 데이터베이스 서비스) 구성 및 온프레미스 이관 대비 |

---

### 2. 테라폼 모듈 작성: 하이브리드 대응형 네트워크

이 단계에서는 재사용 가능한 인프라 설계도인 모듈(Module)을 작성합니다.

**파일 1: `infrastructure/modules/aws-network-spoke/variables.tf**`
모든 변수는 데이터 타입(`type`)과 설명(`description`)을 포함하는 표준 형식을 준수하여 명확성을 높입니다.

```terraform
# 1. 온프레미스 IDC 예약 대역 (모든 하이브리드 설계의 기준점)
# 향후 사내 전산실과의 통신을 위해 미리 정의해 두는 변수입니다.
variable "onprem_cidr" {
  description = "기존에 사용 중인 온프레미스 IDC 네트워크 대역"
  type        = string
  default     = "10.10.0.0/16"
}

# 2. VPC(Virtual Private Cloud, 가상 사설 클라우드) 전체 대역 설정
# 한국은 10.20, 미국은 10.30 등 리전별로 10단위씩 구분하여 할당합니다.
variable "vpc_cidr" {
  description = "AWS VPC의 전체 IP 대역"
  type        = string
  default     = "10.20.0.0/16"
}

# 3. NAT Gateway 생성 여부 제어 스위치
# 현재는 독립된 스포크 망이므로 외부 인터넷 통신을 위해 true로 설정합니다.
# 훗날 트래픽을 통제하는 중앙 허브(Hub) 망이 생기면 이 값을 false로 바꾸어 아키텍처를 전환합니다.
variable "enable_nat" {
  description = "프라이빗 서브넷의 인터넷 통신을 위한 NAT Gateway 활성화 여부"
  type        = bool
  default     = true
}

# 4. 퍼블릭 서브넷 대역 (외부 인터넷과 직접 맞닿는 구역)
# 외부 사용자의 요청을 가장 먼저 받는 로드밸런서 등이 위치합니다.
variable "public_subnets" {
  description = "퍼블릭 서브넷 대역 리스트 (AZ A와 C에 각각 배치)"
  type        = list(string)
  default     = ["10.20.1.0/24", "10.20.2.0/24"]
}

# 5. 프라이빗 서브넷 대역 (외부에서 직접 접근할 수 없는 안전한 구역)
# 실제 기업의 핵심 애플리케이션(EKS 워커 노드)이 실행되는 곳입니다.
variable "private_subnets" {
  description = "EKS 전용 프라이빗 서브넷 대역 리스트 (AZ A와 C에 각각 배치)"
  type        = list(string)
  default     = ["10.20.10.0/24", "10.20.11.0/24"]
}

# 6. 데이터베이스 서브넷 대역 (가장 깊숙하고 안전한 구역)
# 데이터베이스가 위치하며, 온프레미스 대역(10.10)과 혼동을 막기 위해 100번대 IP를 부여했습니다.
variable "database_subnets" {
  description = "RDS 전용 프라이빗 서브넷 대역 리스트"
  type        = list(string)
  default     = ["10.20.100.0/24", "10.20.101.0/24"]
}

```

**파일 2: `infrastructure/modules/aws-network-spoke/main.tf**`
정의한 변수들을 바탕으로 실제 AWS 클라우드에 네트워크와 보안 인프라를 구축하는 핵심 로직입니다.

```terraform

# 0. AWS 프로바이더 설정: 전달받은 region 변수를 사용하여 배포 위치를 확정합니다.
provider "aws" {
  region = var.region
}


# AWS 공식 VPC 모듈을 호출하여 AWS의 권장 표준에 맞춘 네트워크 망을 생성합니다.
module "vpc" {
  source  = "terraform-aws-modules/vpc/aws"
  version = "5.0.0"

  name = "awskr01-spoke-vpc"
  cidr = var.vpc_cidr

  # 한국 리전(ap-northeast-2)의 A와 C 가용 영역을 사용하여 물리적인 서버 장애에 대비(고가용성 확보)합니다.
  azs              = ["ap-northeast-2a", "ap-northeast-2c"]
  public_subnets   = var.public_subnets
  private_subnets  = var.private_subnets
  database_subnets = var.database_subnets

  # 데이터베이스 서브넷 그룹 자동 생성 옵션
  # AWS RDS를 다중 가용 영역(Multi-AZ)으로 배포하려면 반드시 서브넷 그룹이 필요합니다.
  create_database_subnet_group = true

  # NAT Gateway 생성 설정
  # 프라이빗 서브넷 안의 서버들이 외부에서 보안 패치 등을 다운로드하기 위해 필요합니다.
  # [과금 주의] NAT Gateway는 생성된 시간당 약 $0.045의 고정 비용이 발생합니다.
  enable_nat_gateway = var.enable_nat
  
  # 비용 절감을 위해 각 가용 영역마다 만들지 않고, 1개의 NAT Gateway만 생성하여 공유합니다.
  single_nat_gateway = true 

  tags = {
    Project     = "awskr01"
    Terraform   = "true"
    Environment = "spoke"
  }
}

# 온프레미스(10.10.x.x)와 AWS 데이터베이스 간의 마이그레이션(데이터 이관) 및 양방향 복제를 위한 방화벽 규칙입니다.
# 실무에서는 인프라를 한 번 생성하면 수정이 까다로우므로, 이처럼 향후 확장될 연결성(Connectivity)을 미리 코드로 열어두는 것이 좋습니다.
resource "aws_security_group" "db_migration_security_group" {
  name        = "awskr01-db-migration-sg"
  description = "Allow Database replication traffic from On-premises IDC"
  
  # 위에서 만든 VPC 내부에 이 보안 그룹을 위치시킵니다.
  vpc_id      = module.vpc.vpc_id

  # 인바운드(Ingress): 외부에서 AWS 안으로 들어오는 트래픽 통제 규칙
  ingress {
    from_port   = 3306 # MySQL/MariaDB 데이터베이스의 기본 통신 포트
    to_port     = 3306
    protocol    = "tcp"
    
    # 인터넷 전체(0.0.0.0/0)가 아닌, 오직 사내 전산실(온프레미스 10.10 대역)에서만 DB 접근을 허용합니다.
    cidr_blocks = [var.onprem_cidr]
    description = "Allow database replication traffic from On-prem"
  }

  # 아웃바운드(Egress): AWS 안에서 외부로 나가는 트래픽 규칙
  # 데이터베이스가 외부에 응답을 주어야 하므로 나가는 길은 모두 열어둡니다.
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1" # 모든 프로토콜 허용
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name = "awskr01-db-migration-sg"
  }
}

```

---

### 3. 테라그런트 설정: 리전별 배포 파일 (Terragrunt)

작성한 모듈(설계도)에 실제 한국 리전의 값들을 주입하여 실행을 준비하는 파일입니다.

**파일 3: `infrastructure/live/020-spokes/ap-northeast-2/network/terragrunt.hcl**`

```hcl
# 최상위 폴더에 있는 전역 설정(상태 파일을 저장할 S3 백엔드 구성 등)을 자동으로 끌어와 상속받습니다.
include {
  path = find_in_parent_folders()
}

# 적용할 인프라 설계도(모듈)의 위치를 지정합니다.
terraform {
  source = "../../../../modules/aws-network-spoke"
}

# variables.tf에 정의된 변수들에 최종적으로 덮어씌울 실제 값들입니다.
inputs = {
  onprem_cidr      = "10.10.0.0/16"
  vpc_cidr         = "10.20.0.0/16"
  enable_nat       = true
  public_subnets   = ["10.20.1.0/24", "10.20.2.0/24"]
  private_subnets  = ["10.20.10.0/24", "10.20.11.0/24"]
  database_subnets = ["10.20.100.0/24", "10.20.101.0/24"]
}

```

---

### 4. 실습 및 배포 절차 (Daily Workflow)

본격적인 구축을 위해 로컬 PC 터미널에서 다음 명령을 실행합니다.

**Step 1: 1일차 공통 인프라 복구 (사전 작업용 IAM 자원 등)**

```bash
cd /d/projects/awskr01/infrastructure/live/000-prepare/ap-northeast-2
terragrunt apply -auto-approve

```

**Step 2: 2일차 네트워크 및 하이브리드 보안 인프라 구축 실행**

```bash
# 네트워크 실행 디렉토리로 이동
cd ../../../020-spokes/ap-northeast-2/network

# 플러그인 다운로드 및 초기 설정 수행
terragrunt init

# 클라우드에 실제 인프라 배포 (yes 입력하여 승인)
terragrunt apply

```

---

### 5. 작업 종료 및 자원 삭제 (퇴근 절차)

학습이 끝난 후 클라우드 과금을 방지하고 코드를 안전하게 보관하는 절차입니다.

```bash
# 1. 생성된 자원 폐기 (특히 NAT Gateway의 유지 비용을 차단하기 위해 반드시 실행합니다)
terragrunt destroy -auto-approve
cd ../../../000-prepare/ap-northeast-2
terragrunt destroy -auto-approve

# 2. 형상 관리(버전 관리)를 위해 깃허브 원격 저장소에 코드 백업
cd /d/projects/awskr01
git add .
git commit -m "feat: 온프레미스(10.10) 기준 글로벌 네트워크 설계 및 다중 가용영역 기반 하이브리드 인프라 구축 완료"
git push origin main

```

---

### 주석 및 전문 용어 해설

* **CIDR (Classless Inter-Domain Routing, 사이더):** IP 주소를 할당하고 라우팅하는 유연한 방식입니다. `/16`이나 `/24`와 같이 표기하여 네트워크의 크기(사용 가능한 IP 개수)를 결정합니다.
* **NAT Gateway (Network Address Translation Gateway, 네트워크 주소 변환 게이트웨이):** 사설망(Private Subnet) 내부의 서버가 외부 인터넷과 통신할 수 있도록 사설 IP를 공인 IP로 변환해 주는 AWS 관리형 서비스입니다.
* **AZ (Availability Zone, 가용 영역):** 하나의 리전(Region, 예: 서울) 내에 존재하는 물리적으로 완전히 분리된 독립적인 데이터 센터입니다. 2개 이상의 AZ를 사용하면 한 데이터 센터에 화재나 정전이 발생해도 서비스가 중단되지 않습니다.
* **Security Group (보안 그룹):** AWS 내부 자원(EC2, RDS 등)의 앞단에서 들어오고(Ingress) 나가는(Egress) 네트워크 트래픽을 통제하는 방화벽(Firewall) 역할을 합니다.

Next Step: EKS Cluster 구성 및 AWS Load Balancer Controller 배포 준비
========================================


